1. 처리율 제한 장치
  1) 정의
    - 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치
    - 요청을 처리하기 위한 카운터는 캐시에 보관하는 것이 바람직함
  
  2) 장점
    (1) 디도스 공격에 의한 자원 고갈 및 서버 과부하 방지
    (2) API 호출에 대한 비용 절감 가능
    
2. 처리율 제한 알고리즘
  1) 토큰 버킷
    (1) 지정된 용량을 갖는 컨테이너
    (2) 설정된 양의 토큰이 버킷에 주기적으로 채워지고,
        가득찬 버킷에 추가로 공급된 토큰은 버려짐
    (3) 토큰의 수 = 당시의 처리할 수 있는 프로세스의 수
    (4) 버킷 크기와 토큰 공급률 파라미터를 사용하며 적절한 튜닝 필요
    
  2) 누출 버킷
    (1) 고정된 처리율을 가지고 있으며, FIFO Queue로 구현
    (2) 버킷 크기와 처리율 파라미터를 사용하며, 튜닝이 까다로움
    (3) 효율적인 메모리 사용량 및 안정적 출력이 필요한 경우에 적합
    
  3) 고정 윈도우 카운터
    (1) 고정된 간격의 윈도우로 나누고 지정한 카운터 수만큼만 요청을 처리
    (2) 특정한 트래픽 패턴 처리에 적합하나
        윈도우 경계 부근에 트래픽이 몰릴 경우, 시스템 처리 한도보다 많은 양의 요청 발생
    
  4) 이동 윈도우 로그
    (1) 고정 윈도우 카운터의 문제를 해결하는 알고리즘
    (2) 아주 정교한 처리율 제한 알고리즘이지만 다량의 메모리를 사용
    
  5) 이동 윈도우 카운터
    (1) 고정 윈도우 카운터 + 이동 윈도우 로그
    (2) 추정치 계산에 있어 다소 느슨한 알고리즘
    
3. 분산 환경에서의 처리율 제한 장치의 구현 이슈
  1) 경쟁 조건
    (1) 두 대의 서버에서 동시에 카운터가 늘어났을 때, 요청은 2개지만 카운터는 1개만 늘어나는 문제 발생
    (2) LOCK 은 효율이 좋지 못하며, 루아 스크립트, 레디스 자료구조 '정렬 집합' 등이 해결책이 될 수 있음
    
  2) 동기화 이슈
    (1) 하나의 클라이언트에서 두 개의 처리율 제한 장치에 각각 하나씩 요청했을 때, 동기화 이슈 발생
    (2) 레디스와 같은 중앙 집중형 데이터 저장소가 해결책이 될 수 있음
    
  3) 성능 최적화
    (1) 지연시간을 줄이기 위한 다수의 데이터센터 지원
    (2) 제한 장치 간 데이터를 동기화할 때 최종 일관성 모델을 사용
    
  4) 모니터링
    (1) 채택한 처리율 제한 알고리즘이 효과적인가
    (2) 정의한 처리율 제한 규칙이 효과적인가

4. 기타 고려사항
  1) 경성 / 연성 처리율 제한
    (1) 경성 : 요청의 개수는 임계치를 절대 넘을 수 없음 (hard)
    (2) 연성 : 요청 개수는 잠시동안은 임계치를 넘어설 수 있음 (soft)
    
  2) 다양한 계층에서의 처리율 제한
    - OSI 7 기준 다양한 계층에서의 처리율 제한 가능
    
  3) 처리율 제한을 회피하는 방법
    (1) 클라이언트 측 캐시를 사용한 API 호출 횟수 감소
    (2) 짧은 시간동안 많은 요청 금지
    (3) 예외,에러처리 코드를 도입
    (4) 재시도 로직 구현 시 충분한 백오프 시간 부여
